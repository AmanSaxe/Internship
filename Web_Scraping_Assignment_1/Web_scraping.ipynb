{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe9eefb",
   "metadata": {},
   "source": [
    "### Q1. Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ac9281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "def headers(url):\n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    headers=soup.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
    "    print('List all the header tags :', *headers, sep='\\n\\n')\n",
    "headers('https://en.wikipedia.org/wiki/Main_Page')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d83150",
   "metadata": {},
   "source": [
    "### Q2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab551681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def top_movies(url):\n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    yearOfRelease=[]\n",
    "    name=[]\n",
    "    rating=[]\n",
    "    for i in soup.find_all('span',class_=\"secondaryInfo\"):\n",
    "        yearOfRelease.append(i.text.split())\n",
    "    for i in soup.find_all('td',class_=\"titleColumn\"):\n",
    "        name.append(i.text.split('\\n')[2]) \n",
    "    for i in soup.find_all('td',class_=\"ratingColumn imdbRating\"):\n",
    "        rating.append(i.text.split())\n",
    "    df=pd.DataFrame({\"movie name\":name,\"Year of Release\":yearOfRelease,\"Rating\":rating})    \n",
    "    return df\n",
    "top_movies('https://www.imdb.com/chart/top/?ref_=nv_mv_250') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a97d35",
   "metadata": {},
   "source": [
    "### Q3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66cc65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_indian_movies(url):\n",
    "    Page=requests.get(url)\n",
    "    Soup=BeautifulSoup(Page.content)\n",
    "    YearOfRelease=[]\n",
    "    Name=[]\n",
    "    Rating=[]\n",
    "    for i in Soup.find_all('span',class_=\"secondaryInfo\"):\n",
    "        YearOfRelease.append(i.text.split())\n",
    "    for i in Soup.find_all('td',class_=\"titleColumn\"):\n",
    "        Name.append(i.text.split('\\n')[2]) \n",
    "    for i in Soup.find_all('td',class_=\"ratingColumn imdbRating\"):\n",
    "        Rating.append(i.text.split())\n",
    "    df1=pd.DataFrame({\"movie name\":Name,\"Year of Release\":YearOfRelease,\"Rating\":Rating})\n",
    "    return df1\n",
    "top_indian_movies('https://www.imdb.com/india/top-rated-indian-movies/') \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62843e8d",
   "metadata": {},
   "source": [
    "### Q4. Write a python program to scrape product name, price and discounts from https://meesho.com/bags-ladies/pl/p7vbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5251b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bags(url):\n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    product_name=[]\n",
    "    price=[]\n",
    "    discounts=[]\n",
    "    for i in soup.find_all('div',class_=\"sc-dkPtRN ProductList__GridCol-sc-8lnc8o-0 FjWWx jMkQHN\"):\n",
    "        product_name.append(i.text.split('₹')[0])\n",
    "    for i in soup.find_all('div',class_=\"sc-dkPtRN ProductList__GridCol-sc-8lnc8o-0 FjWWx jMkQHN\"):\n",
    "        price.append(i.text.split('₹')[1])\n",
    "    for i in soup.find_all('div',class_=\"sc-dkPtRN ProductList__GridCol-sc-8lnc8o-0 FjWWx jMkQHN\"):\n",
    "        discounts.append(i.text.split('₹')[3]) \n",
    "     \n",
    "    df=pd.DataFrame({'Product_name':product_name,'price':price,'discount':discounts})\n",
    "    return df\n",
    "\n",
    "bags('https://meesho.com/bags-ladies/pl/p7vbp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2ae838",
   "metadata": {},
   "source": [
    "### Q5. Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5a885",
   "metadata": {},
   "source": [
    "   a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beae6cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_rankings(url):\n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    name=[]\n",
    "    points=[]\n",
    "    matches=[]\n",
    "    rating=[]\n",
    "    for i in soup.find_all('span',class_=\"u-show-phablet\"):\n",
    "        name.append(i.text)\n",
    "    \n",
    "    for i in soup.find_all('td',class_=\"rankings-block__banner--matches\"):\n",
    "        matches.append(i.text.split())\n",
    "    for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "        matches.append(i.text.split('\\n')[7]) \n",
    "    for i in soup.find_all('td',class_=\"rankings-block__banner--points\"):\n",
    "        points.append(i.text)    \n",
    "    for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "        points.append(i.text.split('\\n')[8]) \n",
    "   \n",
    "    for i in soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "        rating.append(i.text.split()) \n",
    "    for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "        rating.append(i.text.split('\\n')[9])    \n",
    "    print(name)\n",
    "    print(matches)\n",
    "    print(points)\n",
    "    print(rating)\n",
    "team_rankings('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca474c5",
   "metadata": {},
   "source": [
    "b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b129833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batsman_rankings(url):\n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    plname=[]\n",
    "    for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "        plname.append(i.text.split('\\n')[13])\n",
    "    team=[]\n",
    "    for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "        team.append(i.text.split('\\n')[17])    \n",
    "    rating=[]\n",
    "    for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "        rating.append(i.text.split('\\n')[19]) \n",
    "    print(plname,team,rating)\n",
    "batsman_rankings('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facef5eb",
   "metadata": {},
   "source": [
    "c)Top 10 ODI bowlers along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6336af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bowler_rankings(url):\n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    plname=[]\n",
    "    for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "        plname.append(i.text.split('\\n')[13])\n",
    "    team=[]\n",
    "    for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "        team.append(i.text.split('\\n')[17])    \n",
    "    rating=[]\n",
    "    for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "        rating.append(i.text.split('\\n')[19]) \n",
    "    print(plname,team,rating)\n",
    "bowler_rankings('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5790619e",
   "metadata": {},
   "source": [
    "### Q6. Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ca3517",
   "metadata": {},
   "source": [
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_rankings(url):\n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    name=[]\n",
    "    points=[]\n",
    "    matches=[]\n",
    "    rating=[]\n",
    "    for i in soup.find_all('span',class_=\"u-show-phablet\"):\n",
    "        name.append(i.text)\n",
    "    \n",
    "    for i in soup.find_all('td',class_=\"rankings-block__banner--matches\"):\n",
    "        matches.append(i.text.split())\n",
    "    for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "        matches.append(i.text.split('\\n')[7]) \n",
    "    for i in soup.find_all('td',class_=\"rankings-block__banner--points\"):\n",
    "        points.append(i.text)    \n",
    "    for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "        points.append(i.text.split('\\n')[8]) \n",
    "   \n",
    "    for i in soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "        rating.append(i.text.split()) \n",
    "    for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "        rating.append(i.text.split('\\n')[9])    \n",
    "    print(name)\n",
    "    print(matches)\n",
    "    print(points)\n",
    "    print(rating)\n",
    "team_rankings('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1c8428",
   "metadata": {},
   "source": [
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b086c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batsman_rankings(url):\n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    plname=[]\n",
    "    for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "        plname.append(i.text.split('\\n')[13])\n",
    "    team=[]\n",
    "    for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "        team.append(i.text.split('\\n')[17])    \n",
    "    rating=[]\n",
    "    for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "        rating.append(i.text.split('\\n')[19]) \n",
    "    print(plname,team,rating)\n",
    "batsman_rankings('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf31fe7a",
   "metadata": {},
   "source": [
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9ffcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bowler_rankings(url):\n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    plname=[]\n",
    "    for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "        plname.append(i.text.split('\\n')[13])\n",
    "    team=[]\n",
    "    for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "        team.append(i.text.split('\\n')[17])    \n",
    "    rating=[]\n",
    "    for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "        rating.append(i.text.split('\\n')[19]) \n",
    "    print(plname,team,rating)\n",
    "bowler_rankings('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0c3306",
   "metadata": {},
   "source": [
    "### Q7. Write a python program to scrape details of all the posts from coreyms.com. Scrape the heading, date, content and the code for the video from the link for the youtube video from the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62d4eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coreyms(url):\n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    heading=[]\n",
    "    date=[]\n",
    "    content=[]\n",
    "    videocode=[]\n",
    "    for i in soup.find_all('a',class_=\"entry-title-link\"):\n",
    "        heading.append(i.text)\n",
    "    for i in soup.find_all('time',class_=\"entry-time\"):\n",
    "        date.append(i.text)\n",
    "    for i in soup.find_all('div',class_=\"entry-content\"):\n",
    "        content.append(i.text.split(','))\n",
    "    for i in soup.find_all('iframe'):\n",
    "        videocode.append(i)    \n",
    "    \n",
    "    print(heading,\"\\n\")\n",
    "    print(date,\"\\n\")\n",
    "    print(content,\"\\n\")\n",
    "    print(videocode)\n",
    "    \n",
    "coreyms('https://coreyms.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c345d2c",
   "metadata": {},
   "source": [
    "### Q8. Write a python program to scrape house details from mentioned URL. It should include house title, location, area, EMI and price from https://www.nobroker.in/ .Enter three localities which are Indira Nagar, Jayanagar, Rajaji Nagar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5571dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flats(url):\n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    heading=[]\n",
    "    area=[]\n",
    "    price=[]\n",
    "    for i in soup.find_all('span',itemprop=\"name\"):\n",
    "        heading.append(i.text)\n",
    "    for i in soup.find_all('div',class_=\"nb__1EwQz\"):\n",
    "        area.append(i.text)\n",
    "    for i in soup.find_all('div',class_=\"nb__27aDo\"):\n",
    "        price.append(i.text)        \n",
    "        \n",
    "    print(heading,\"\\n\")\n",
    "    print(area,'\\n')\n",
    "    print(price)\n",
    "\n",
    "flats('https://www.nobroker.in/property/rent/mumbai/multiple?searchParam=W3sibGF0IjoxNy40NDc0NDc1LCJsb24iOjc4LjM1NjkyNzUsInBsYWNlSWQiOiJDaElKZzVwcF9KU1R5enNSaHBYNzU2M2VkX2ciLCJwbGFjZU5hbWUiOiJJbmRpcmEgTmFnYXIifSx7ImxhdCI6MTcuNTAwMDcyOCwibG9uIjo3OC40MDUxOTU5OTk5OTk5OSwicGxhY2VJZCI6IkNoSUpzWEZxb3VtUnl6c1JiWlZ5ZGVqMkdKSSIsInBsYWNlTmFtZSI6IkpheWFuYWdhciBDb2xvbnkifSx7ImxhdCI6MTkuMjE1NjQ0NiwibG9uIjo3My4wODQzNTk5LCJwbGFjZUlkIjoiQ2hJSlVjODRHU0ctNXpzUnRwbnVJZFFwMnRJIiwicGxhY2VOYW1lIjoiUmFqYWppIFJvYWQsIFJhamFqaSBQYXRoIn1d&radius=2.0&sharedAccomodation=0&city=mumbai&locality=Indira%20Nagar,&locality=Jayanagar%20Colony,&locality=Rajaji%20Road,%20Rajaji%20Path')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecb25c6",
   "metadata": {},
   "source": [
    "### Q9. Write a python program to scrape mentioned details from dineout.co.in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a303a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restaurants(url):\n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    Restaurantname1=[]\n",
    "    Restaurantloc=[]\n",
    "    Restaurantrating=[]\n",
    "    imageurl=[]\n",
    "    cuisines=[]\n",
    "    for i in soup.find_all('a',class_='restnt-name ellipsis'):\n",
    "        Restaurantname1.append(i.text)\n",
    "    for i in soup.find_all('div',class_='restnt-loc ellipsis'):\n",
    "        Restaurantloc.append(i.text.split(','))\n",
    "    for i in soup.find_all('div',class_='img-wrap'):\n",
    "        Restaurantrating.append(i.text)\n",
    "    for i in soup.find_all('img',class_='no-img'):\n",
    "        imageurl.append(i)\n",
    "    for i in soup.find_all('span',class_='double-line-ellipsis'):\n",
    "        cuisines.append(i.text.split('|')[1])\n",
    "    print(Restaurantname1,'\\n')\n",
    "    print(Restaurantloc,'\\n')\n",
    "    print(Restaurantrating,'\\n')\n",
    "    print(imageurl,'\\n')\n",
    "    print(cuisines)\n",
    "\n",
    "restaurants('https://www.dineout.co.in/delhi-restaurants?search_str=chinese')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36c3bcd",
   "metadata": {},
   "source": [
    "### Q10. Write a python program to scrape first 10 product details which include product name , price , Image URL from https://www.bewakoof.com/women-tshirts?ga_q=tshirts ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3d3fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def products(url):\n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    Productname=[]\n",
    "    Productprice=[]\n",
    "    image=[]\n",
    "    for i in soup.find_all('h3',id):\n",
    "        Productname.append(i.text.split(','))\n",
    "    for i in soup.find_all('div',class_='productPriceBox clearfix'):\n",
    "        Productprice.append(i.text.split('₹')[2])   \n",
    "    for i in soup.find_all('img',src=True):\n",
    "        image.append(i)\n",
    "    print(Productname,'\\n')\n",
    "    print(Productprice,'\\n')\n",
    "    print(image)\n",
    "products('https://www.bewakoof.com/women-tshirts?ga_q=tshirts%20.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
